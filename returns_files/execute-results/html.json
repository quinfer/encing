{
  "hash": "b46c2ebc9f086e217c8fe2ddc8dd36c9",
  "result": {
    "markdown": "---\ntitle: \"Understanding Financial Data and Asset Returns\"\nauthor: \"Barry Quinn\"\neditor: visual\nbibliography: references.bib\n---\n\n\n![](images/logos/DALL·E%202024-01-18%2016.32.37%20-%20Create%20a%20professional%20logo%20for%20an%20advanced%20financial%20data%20analytics%20course.%20The%20design%20should%20be%20vibrant,%20with%20a%20medium%20level%20of%20detail,%20balancing%20com.png){width=\"30%\" style=\"float: left; margin-right: 10px;\"}\n\nFinancial time series, such as asset prices, exchange rates, and interest rates, are fundamental in econometric analysis. Unlike prices, returns are more commonly used due to their desirable statistical properties, such as stationarity and scale independence. This chapter will explore various aspects of financial returns.\n\n# We transform prices to returns\n\nIn financial econometrics, the focus on analyzing returns rather than prices is both theoretically and practically driven. Here's a detailed explanation based on the book @lo1997econometrics\n\n## Theoretical Reasons\n\n1.  **Stationarity**: Financial time series of prices are typically non-stationary, meaning their statistical properties (like mean and variance) change over time. This non-stationarity violates the basic assumptions of many econometric models. Returns, calculated as the percentage change in prices, are more likely to be stationary. Stationary data is crucial for applying many statistical and econometric techniques, as it ensures that the model's parameters are constant over time.\n\n2.  **Difficulties with Non-Stationary Data**: Working with non-stationary data can lead to spurious regression problems, where relationships between variables appear significant even when they are not. Returns typically exhibit weaker forms of non-stationarity compared to prices, reducing the risk of such misleading results.\n\n3.  **Economic Theory Alignment**: Returns represent the reward for bearing risk, which is a fundamental concept in financial economics. Analyzing returns aligns more closely with economic theories that focus on risk and reward, such as the Capital Asset Pricing Model (CAPM) and Efficient Market Hypothesis (EMH).\n\n4.  **Volatility Modeling**: Returns facilitate the modeling of volatility, a key aspect in financial markets. Models like GARCH (Generalized Autoregressive Conditional Heteroskedasticity) are designed to capture the volatility clustering often observed in returns, which is not as apparent when analyzing prices directly.\n\n## Transaction Costs\n\n1.  **Round Trip Transaction Costs**: This concept usually refers to the total costs incurred in completing a full investment cycle – buying and then subsequently selling a financial asset. These costs include brokerage fees, bid-ask spreads, taxes, and other transaction expenses.\n\n2.  **Impact on Returns Analysis**: When considering round trip transaction costs in the context of financial markets, it's important to analyze returns rather than prices. This is because the actual return on an investment needs to account for these costs. For instance, even if an asset's price appreciates, the net return might be lower (or even negative) after accounting for transaction costs.\n\n3.  **Modeling and Risk Assessment**: In econometric models, incorporating transaction costs is crucial for realistic risk and return assessments. These costs can significantly impact the viability and attractiveness of trading strategies, especially those involving frequent transactions.\n\n4.  **Behavioral Implications**: Transaction costs also influence investor behavior. High costs might deter frequent trading, thereby affecting the liquidity and price volatility of assets.\n\n## Practical Reasons\n\n1.  **Comparability**: Returns standardize the performance across different assets, allowing for meaningful comparisons. For instance, a \\$5 increase in a \\$10 stock is a 50% return, whereas the same \\$5 increase in a \\$100 stock is only a 5% return. Analyzing prices would not capture this difference in performance.\n\n2.  **Simplicity in Modeling**: Modeling returns simplifies the mathematical complexity involved in dealing with non-stationary price series. This simplification allows for more straightforward interpretation and application of models.\n\n3.  **Risk Management**: In financial risk management, the focus is often on the variability of returns (i.e., risk) rather than absolute price levels. Analyzing returns directly aligns with this focus, aiding in the development of risk management strategies.\n\n4.  **Efficient Market Considerations**: In efficient markets, it is believed that all available information is already reflected in current prices. Therefore, the focus is on changes in prices (returns), which reflect new information, rather than on the price levels themselves.\n\n\n# Asset Returns\n\n## One-Period Simple Returns\n\nSimple returns represent the percentage change in asset price over a single period and are calculated as follows:\n\n$$ R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} $$\n\nwhere ( R_t ) is the return at time ( t ), ( P_t ) is the price at time ( t ), and ( P\\_{t-1} ) is the price at time ( t-1 ).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tsfe)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: tidyverse\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\n# Assuming 'prices' is a vector of asset prices\nprices<-monte_carlo_paths()\nprices<-filter(prices, possible_path_no==1)\n\nreturns <- na.omit(diff(prices$sample_path)) / lag(prices$sample_path, 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in na.omit(diff(prices$sample_path))/lag(prices$sample_path, 1): longer\nobject length is not a multiple of shorter object length\n```\n:::\n\n```{.r .cell-code}\nreturns <- na.omit(returns)\n```\n:::\n\n\n## Multiperiod Simple Returns\n\nFor multiple periods, simple returns are compounded. The formula for a return over ( n ) periods is:\n\n$$ R_{t, t+n} = \\prod_{i=1}^{n} (1 + R_{t+i}) - 1 $$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# To calculate multiperiod returns\nmultiperiod_return <- prod(1 + returns) - 1\n```\n:::\n\n\n## Time Interval Considerations\n\nThe time interval of returns (daily, monthly, yearly) significantly impacts their magnitude and volatility. Annualizing returns involves scaling them to a yearly basis, usually by multiplying (for simple returns) or exponentiation (for log returns) by the number of periods per year.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_return <- returns\n# Annualizing daily returns (assuming 252 trading days in a year)\nannualized_return <- (1 + daily_return) ^ 252 - 1\n```\n:::\n\n\n## Continuously Compounded Returns\n\nContinuously compounded, or log returns, are computed as the natural logarithm of the price ratio:\n\n$$ r_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right) $$\n\nLog returns are time-additive, making them suitable for multi-period returns calculation and econometric modeling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_returns <- diff(log(prices$sample_path))\nlog_returns <- na.omit(log_returns)\n```\n:::\n\n\n## Portfolio Returns\n\nPortfolio returns are the weighted average of individual asset returns, reflecting the portfolio composition.\n\n### Simple Portfolio Returns\n\nThe simple return of a portfolio is the sum of the weighted returns of each asset.\n\n$$ R_{portfolio} = \\sum_{i=1}^{N} w_i R_i $$\n\nwhere ( w_i ) is the weight of the ( i\\^{th} ) asset in the portfolio, and ( R_i ) is its return.\n\n\n``` r\n# Assuming 'weights' is a vector of portfolio weights and 'returns' is a matrix of returns\nportfolio_return <- rowSums(weights * returns)\n```\n\n### Log Portfolio Returns\n\nFor log returns, the portfolio return is not a simple weighted sum but can be approximated for small individual returns.\n\n## Adjustments for Dividend Payments\n\nTotal return, considering both price changes and dividends, gives a more complete picture of an asset's performance.\n\n$$ R_{total} = \\frac{P_t + D_t - P_{t-1}}{P_{t-1}} $$\n\nwhere ( D_t ) is the dividend paid at time ( t ).\n\n## Excess Returns\n\nExcess return is the return of an asset over and above a benchmark or risk-free rate, crucial in risk-adjusted performance analysis.\n\n$$ R_{excess} = R_{asset} - R_{benchmark} $$\n\n## Bond Yields and Prices\n\nThis section would cover various bond types and their yield calculations, including Yield to Maturity (YTM) and Current Yield.\n\n## Implied Volatility\n\nDiscuss implied volatility in options pricing, particularly with the Black-Scholes model. Introduce the CBOE VIX as a real-world application.\n\n\n# Overlapping Returns and Autocorrelation\n\nA common approach in empirical asset pricing research involves using time-series data of asset returns. For example, a researcher may collect daily stock return data over several years to study predictive signals, risk factors, or other relationships. However, the use of overlapping multiperiod returns can introduce statistical complications @lo1990econometric.  \n\nThe issue arises because adjacent return observations share common days, inducing autocorrelation in the time-series data. For instance, 20-day returns with a 1-day shift comprise 19 identical daily returns. This overlap across return intervals leads to spurious correlation, violating assumptions of independently and identically distributed (i.i.d) observations under classical statistical models.\n\nConsequences include biased coefficient estimates, understated standard errors, and over-rejection of null hypotheses during hypothesis testing. In effect, the observed sample size overstates the effective size for calculating precision and confidence levels. The series appears to contain more information than is actually present. \n\nConsider the simulated autocorrelated return process:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)  \nr <- arima.sim(model=list(ar=0.5), n=100)\nacf(r)  \n```\n\n::: {.cell-output-display}\n![](returns_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nRegressing another random series x onto r yields biased estimates and t-stats: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(100) \ny <- x + r + rnorm(100)\nsummary(lm(y ~ x))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.8639 -0.8560  0.0053  1.0721  3.8671 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.2624     0.1483   1.769     0.08 .  \nx             0.9920     0.1483   6.687 1.41e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.483 on 98 degrees of freedom\nMultiple R-squared:  0.3133,\tAdjusted R-squared:  0.3063 \nF-statistic: 44.72 on 1 and 98 DF,  p-value: 1.407e-09\n```\n:::\n:::\n\n\nThere are several potential approaches for handling overlapping data:  \n\n1. Utilize non-overlapping returns - e.g. annual instead of monthly. This eliminates overlap bias but reduces sample size considerably.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nr<-tibble(r)\nslices<-seq(1, nrow(r), 12)\nr_annual <- r |> slice(slices)   \n```\n:::\n\n\n2. Model the autocorrelation structure like an ARMA process. Specify this correlation during estimation for properly adjusted estimates and standard errors. However, this relies on correctly specifying the autocorrelation structure.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nar1 <- arima(y, xreg=x, order=c(1,0,0))  \n```\n:::\n\n\n3. Employ statistical techniques robust to certain autocorrelation structures, such as heteroskedasticity and autocorrelation (HAC) corrections to standard errors. For example, Newey-West standard errors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: zoo\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'zoo'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n:::\n\n```{.r .cell-code}\nlibrary(sandwich) \nr <- arima.sim(model=list(ar=0.5), n=100)\nx <- rnorm(100)\ny <- x + r + rnorm(100)\n\nmod <- lm(y ~ x)\n\ncoeftest(mod, vcov = NeweyWest(mod))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(>|t|)    \n(Intercept) 0.057822   0.191822  0.3014    0.7637    \nx           0.973118   0.125354  7.7629 8.101e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nOverlapping returns has relevance in many empirical finance settings but warrants additional consideration during econometric modeling and analysis. Failing to account for the induced autocorrelation can undermine results and conclusions. For example, @richardson1991tests investigate daily stock return regressions and find that positive autocorrelation from overlapping intervals can falsely indicate significant predictability when the true process contains only white noise.\n\n\n## References\n\n",
    "supporting": [
      "returns_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}