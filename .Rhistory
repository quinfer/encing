done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- argmax(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices))))), k = 1)), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
# Implement Q-learning
for (episode in seq(num_episodes)) {
state <- head(as.numeric(as.matrix(lag(t(as.matrix((data.frame(Prices = prices))))), k = 1)), 1)
done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- argmax(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices))))), k = 1)), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.frame(Prices = prices))))), k = 1), 1)
#devtools::install_github("smilesun/rlR")
#library(rl)
# Define state space
state_size <- ncol(as.matrix(lag(t(as.matrix(data.frame(Prices = prices)))), k = 1))
action_size <- 2
# Initialize Q matrix
Q <- matrix(rep(NA, state_size * action_size), nrow = state_size, ncol = action_size)
# Set hyperparameters
alpha <- 0.1 # Learning rate
epsilon <- 0.1 # Exploration probability
num_episodes <- 1000 # Number of episodes
discount_factor <- 0.95 # Discount factor
# Implement Q-learning
for (episode in seq(num_episodes)) {
state <- head(as.numeric(as.matrix(lag(t(as.matrix((data.frame(Prices = prices))))), k = 1)), 1)
done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- which.max(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.frame(Prices = prices))))), k = 1), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
reticulate::repl_python()
library(lme4) # For REM & HLM
library(plm)   # For FEM
set.seed(123)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 6
sectors <- 5
# Generate synthetic dataset
parent_id <- rep(1:n_parents, each = subsidiary_per_parent * years)
time <- rep(seq(1980 + year - 1, length.out = years), times = n_parents * subsidiary_per_parent)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 6
sectors <- 5
# Generate synthetic dataset
parent_id <- rep(1:n_parents, each = subsidiary_per_parent * years)
time <- rep(seq(1980 + years - 1, length.out = years), times = n_parents * subsidiary_per_parent)
sector <- sample(rep(1:sectors, each = subsidiary_per_parent * years / sectors))
# True sector-specific intercepts
beta_true <- c(-0.3, 0.2, 0.5, -0.8, 0.1)
# Parent company fixed effects
alpha_parent <- rnorm(n_parents)
# Simulate sales growth rates
sigma_error <- 0.5
y <- alpha_parent[parent_id] + beta_true[sector] + rnorm(length(parent_id), sd = sigma_error)
data <- data.frame(y, parent_id, sector, time)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
View(data)
View(data)
table(index(data), useNA = "ifany")
table(index(data), useNA = "ifany")
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id","sector", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id","sector", "time"))
View(data)
data |> distinct(parent_id,sector,time)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 6
sectors <- 5
# Generate synthetic dataset
parent_id <- rep(1:n_parents, each = subsidiary_per_parent * years* sectors)
time <- rep(seq(1980 + years - 1, length.out = years), times = n_parents * subsidiary_per_parent * sectors)
sector <- sample(rep(1:sectors, each = subsidiary_per_parent * years / sectors))
# True sector-specific intercepts
beta_true <- c(-0.3, 0.2, 0.5, -0.8, 0.1)
# Parent company fixed effects
alpha_parent <- rnorm(n_parents)
# Simulate sales growth rates
sigma_error <- 0.5
y <- alpha_parent[parent_id] + beta_true[sector] + rnorm(length(parent_id), sd = sigma_error)
data <- data.frame(y, parent_id, sector, time)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id","sector", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
View(data)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 6
sectors <- 5
# Generate synthetic dataset
parent_id <- rep(1:n_parents, each = subsidiary_per_parent * years / sectors)
time <- rep(seq(1980 + years - 1, length.out = years), times = n_parents * subsidiary_per_parent  / sectors)
sector <- sample(rep(1:sectors, each = subsidiary_per_parent * years / sectors))
# True sector-specific intercepts
beta_true <- c(-0.3, 0.2, 0.5, -0.8, 0.1)
# Parent company fixed effects
alpha_parent <- rnorm(n_parents)
# Simulate sales growth rates
sigma_error <- 0.5
y <- alpha_parent[parent_id] + beta_true[sector] + rnorm(length(parent_id), sd = sigma_error)
data <- data.frame(y, parent_id, sector, time)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 6
sectors <- 5
# Generate synthetic dataset
parent_id <- rep(1:n_parents, each = subsidiary_per_parent * years)
time <- rep(seq(1980 + years - 1, length.out = years), times = n_parents * subsidiary_per_parent)
sector <- sample(rep(1:sectors, each = subsidiary_per_parent * years / sectors))
# True sector-specific intercepts
beta_true <- c(-0.3, 0.2, 0.5, -0.8, 0.1)
# Parent company fixed effects
alpha_parent <- rnorm(n_parents)
# Simulate sales growth rates
sigma_error <- 0.5
y <- alpha_parent[parent_id] + beta_true[sector] + rnorm(length(parent_id), sd = sigma_error)
data <- data.frame(y, parent_id, sector, time)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id","sector", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
cat("Fixed Effect Estimates:\n")
print(coef(fe_model)[-1], digits = 3)
cat("\n\nRandom Effect Estimates:\n")
print(fixef(re_model), digits = 3)
cat("\n\nHierarchical Linear Model Estimates:\n")
print(ranef(hlm_model)$parent_id[[1]], digits = 3)
print(ranef(hlm_model)$parent_id$sector, digits = 3)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id), data)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "time"))
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id), data)
cat("Fixed Effect Estimates:\n")
print(coef(fe_model)[-1], digits = 3)
cat("\n\nRandom Effect Estimates:\n")
print(fixef(re_model), digits = 3)
cat("\n\nHierarchical Linear Model Estimates:\n")
print(ranef(hlm_model)$parent_id[[1]], digits = 3)
print(ranef(hlm_model)$parent_id$sector, digits = 3)
# Number of parents, number of subsidiaries per parent, number of years, and number of sectors
n_parents <- 100
subsidiary_per_parent <- 4
years <- 10
sectors <- 5
# Generate IDs
parent_id <- rep(1:n_parents, each=subsidiary_per_parent*years)
# Generate time variable
year <- rep(2015:2024, times=n_parents*subsidiary_per_parent)
# Generate sectors
sector <- sample(rep(1:sectors, each=subsidiary_per_parent*years/sectors))
# True sector effects
beta <- rnorm(sectors, 0, 1)
# Parent effects
alpha <- rnorm(n_parents, 0, 1)
# Simulate growth rates
sigma <- 0.05
y <- alpha[parent_id] + beta[sector] + rnorm(length(parent_id), sd=sigma)
# Create dataset
data <- data.frame(y, parent_id, sector, year)
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "time"))
# Fit fixed effect model
fe_model <- plm(y ~ factor(sector), data, index = c("parent_id", "year"))
# Fit fixed effect model
index <- c("parent_id", "row_number()", "year")
fe_model <- plm(y ~ factor(sector), data, index = index)
# Fit fixed effect model
# Create subsidiary id
sub_id <- 1:n_parents*subsidiary_per_parent*years
data$sub_id <- sub_id
index <- c("parent_id", "sub_id", "year")
# Model
fe_model <- plm(y ~ factor(sector), data, index = index)
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id), data)
# Fit fixed effect model
# Create subsidiary id
sub_id <- 1:n_parents*subsidiary_per_parent*years
data$sub_id <- sub_id
index <- c("parent_id", "sub_id", "year")
# Model
fe_model <- plm(y ~ factor(sector), data, index = index)
# Fit random effect model
re_model <- lmer(y ~ factor(sector) + (1 | parent_id), data)
# Fit hierarchical linear model
hlm_model <- lmer(y ~ factor(sector) + (1|parent_id/sector), data)
cat("Fixed Effect Estimates:\n")
print(coef(fe_model)[-1], digits = 3)
cat("\n\nRandom Effect Estimates:\n")
print(fixef(re_model), digits = 3)
cat("\n\nHierarchical Linear Model Estimates:\n")
print(ranef(hlm_model)$parent_id[[1]], digits = 3)
print(ranef(hlm_model)$parent_id$sector, digits = 3)
quarto preview
# R Example: Time Series Analysis of Stock Prices
library(quantmod)
# Fetching stock data
getSymbols("AAPL", src = "yahoo", from = "2020-01-01", to = "2023-12-31")
```R
# R Example: Time Series Analysis of Stock Prices
library(quantmod)
# Fetching stock data
getSymbols("AAPL", src = "yahoo", from = "2020-01-01", to = "2023-12-31")
# Analyzing the closing prices
aapl_close <- Cl(AAPL)
# Plotting the closing prices
plot(aapl_close, main = "AAPL Closing Prices", col = "blue")
# Using a simple time series model - Moving Average
aapl_ma <- rollmean(aapl_close, k = 50, fill = NA)
lines(aapl_ma, col = "red")
# More advanced analysis - ARIMA model
library(forecast)
aapl_arima <- auto.arima(aapl_close)
forecast_aapl <- forecast(aapl_arima, h = 30)
plot(forecast_aapl)
Sys.Date()
# Perform a Bayesian update for stock price prediction
prior <- dbeta(1,1,1) # Uniform prior
likelihood <- dbinom(6, size=10, prob=0.5)
posterior <- prior * likelihood
posterior
#install.packages("RPostgreSQL")
library(RPostgreSQL)
install.packages("RPostgreSQL")
#install.packages("RPostgreSQL")
library(RPostgreSQL)
your_wrds_username="bquinn"
your_wrds_password="adamskiquinn"
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_password,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_username,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_username,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
your_wrds_username="bquinn"
your_wrds_password="adamskiquinn"
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_username,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
#install.packages("RPostgreSQL")
library(RPostgreSQL)
rm(wrds)
.rs.restartR()
#install.packages("RPostgreSQL")
library(RPostgreSQL)
your_wrds_username="bquinn"
your_wrds_password="adamskiquinn"
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_username,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
your_wrds_username="bquinn"
your_wrds_password="hydT6K4pPyFZk8m"
wrds <- dbConnect(PostgreSQL(),
user = your_wrds_username,
password = your_wrds_password,
host = "wrds-pgdata.wharton.upenn.edu",
port = 9737,
dbname = "wrds")
your_wrds_username="bquinn"
your_wrds_password="hydT6K4pPyFZk8m"
wrds <- dbConnect(
Postgres(),
host = "wrds-pgdata.wharton.upenn.edu",
dbname = "wrds",
port = 9737,
sslmode = "require",
user = Sys.getenv(your_wrds_username),
password = Sys.getenv(your_wrds_password)
)
your_wrds_username="bquinn"
your_wrds_password="hydT6K4pPyFZk8m"
wrds <- dbConnect(
Postgres(),
host = "wrds-pgdata.wharton.upenn.edu",
dbname = "wrds",
port = 9737,
sslmode = "require",
user = your_wrds_username,
password = your_wrds_password
)
library(tsfe)
remotes::install_github("quinfer/tsfe")
# Random Walk Simulation in R
set.seed(0)  # For reproducibility
n_steps <- 1000  # Number of steps in the random walk
initial_price <- 100  # Starting price
drift <- 0.0002  # Drift term, representing the expected return
volatility <- 0.01  # Volatility term, representing the standard deviation of returns
# Generate random steps, either -1 or 1
steps <- sample(c(-1, 1), size = n_steps, replace = TRUE)
steps[1] <- 0  # The first step is 0 so that the series starts at the initial price
# Convert steps to returns
returns <- drift + volatility * steps
# Calculate the price series
prices <- initial_price * exp(cumsum(returns))
# Plotting the random walk
plot(prices, type = 'l', main = 'Random Walk Representation of a Financial Time Series',
xlab = 'Time Steps', ylab = 'Price', col = 'blue')
daily_returns<-returns
# Annualizing daily returns (assuming 252 trading days in a year)
annualized_return <- (1 + daily_return) ^ 252 - 1
daily_return <- returns
# Annualizing daily returns (assuming 252 trading days in a year)
annualized_return <- (1 + daily_return) ^ 252 - 1
annualized_return
plot(annualized_return)
plot(annualized_return, type = 'l', main = 'Random Walk Representation of a Financial Time Series',
xlab = 'Time Steps', ylab = 'Price', col = 'blue')
# Assuming a package like quantmod is installed
library(quantmod)
# Get stock data
getSymbols("AAPL", src = "yahoo", from = "2020-01-01", to = "2020-12-31")
apple_stock <- as.data.frame(AAPL)
# Handling missing values
stock_prices <- na.omit(apple_stock)
# Data transformation with dplyr
library(dplyr)
# Example: Aggregating average monthly prices for Apple stock
apple_monthly_avg <- apple_stock %>%
mutate(month = format(index(apple_stock), "%Y-%m")) %>%
group_by(month) %>%
summarise(avg_close = mean(AAPL.Close, na.rm = TRUE))
formatted_ts <- apple_stock %>%
xts::period.apply(., endpoints(., period = "months"), mean) %>%
na.omit() %>%
mutate(month = format(index(.), "%Y-%m"))
library(TTR)
library(xts)
formatted_ts <- apple_stock %>%
xts::period.apply(., endpoints(., period = "months"), mean) %>%
na.omit() %>%
mutate(month = format(index(.), "%Y-%m"))
symbol <- "AAPL"
start_date <- as.Date("2020-01-01")
end_date <- Sys.Date()
getSymbols(symbol, src = "yahoo", from = start_date, to = end_date)
close_prices <- Ad(AAPL)["2020-01-01/"]
monthly_averages <- period.apply(close_prices, endpoints(close_prices, on = "months"), mean)
# Get stock data
getSymbols(symbol, src = "yahoo", from = start_date, to = end_date)
aapl_xts <- AAPL['2020-01-01/']
aapl_df <- fortify.zoo(aapl_xts)
aapl_cleaned <- aapl_df |>
clean_names() |>
select(-order.column) |>
pivot_wider(names_from = variable, values_from = value)
# Assuming a package like quantmod is installed
library(quantmod)
library(tidyverse)
library(tidyverse)
library(timetk)
library(tidyverse)
library(timetk)
library(janitor)
# Get stock data
getSymbols(symbol, src = "yahoo", from = start_date, to = end_date)
aapl_xts <- AAPL['2020-01-01/']
aapl_df <- fortify.zoo(aapl_xts)
aapl_cleaned <- aapl_df |>
clean_names() |>
select(-order.column) |>
pivot_wider(names_from = variable, values_from = value)
aapl_df
# Handling missing values
stock_prices <- na.omit(apple_df)
# Handling missing values
stock_prices <- na.omit(aapl_df)
# Handling missing values
stock_prices <- (aapl_df) |> drop_na()
aapl_monthly <- aapl_df |>
mutate(date = ymd(Index)) |>
group_by(year = floor_date(date, unit = "year"), month = ceiling_date(date, unit = "month") - days(1)) |>
summarize(mean_price = mean(Adjusted)) |>
ungroup() |>
arrange(year, month)
aapl_monthly <- aapl_df |>
mutate(date = ymd(Index)) |>
group_by(year = floor_date(date, unit = "year"), month = ceiling_date(date, unit = "month") - days(1)) |>
summarize(mean_price = mean(AAPL.Adjusted)) |>
ungroup() |>
arrange(year, month)
print(head(aapl_monthly))
symbol="AAPL"
# Get stock data
getSymbols(symbol, src = "yahoo", from = start_date, to = end_date)
aapl_xts <- AAPL['2020-01-01/']
aapl_df <- fortify.zoo(aapl_xts)
# Linear time trend regression on stock prices
model <- lm(AAPL.Close ~ Index, data = aapl_df)
summary(model)
training_index <- createDataPartition(aapl_df$AAPL.Close, p = 0.8, list = FALSE)
# Machine learning with the caret package
library(caret)
# Preparing data (assuming 'stock_prices' has relevant features)
set.seed(123)
training_index <- createDataPartition(aapl_df$AAPL.Close, p = 0.8, list = FALSE)
training_data <- stock_prices[training_index, ]
testing_data <- stock_prices[-training_index, ]
# Train a linear regression model
model <- train(Price ~ ., data = training_data, method = "lm")
# Train a linear regression model
model <- train(AAPL.close ~ AAPL.Volume  ., data = training_data, method = "lm")
# Reading a CSV file from the directory assuming it is name "stock_prices.csv"
global_factor_data <- read.csv(file = "[world]_[all_themes]_[daily]_[vw_cap].csv")
View(global_factor_data)
