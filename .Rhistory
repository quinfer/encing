journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
gsub("/", "_", doi), authors, title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author_surname <- strsplit(authors[1], " ")[[1]][1] # Extract the surname of the first author
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
bibtex_label <- paste0(first_author_surname, year)
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
entries <- vector("list", length(s_results))
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author_surname <- strsplit(authors[1], " ")[[1]][1] # Extract the surname of the first author
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
bibtex_label <- paste(first_author_surname,year,collapse = "")
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
paste("A","B",collapse = TRUE)
paste("A","B",collapse = "_")
paste("A","B",collapse = "")
paste0("A","B",collapse = "")
entries <- vector("list", length(s_results))
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author_surname <- strsplit(authors[1], " ")[[1]][1] # Extract the surname of the first author
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
bibtex_label <- paste0(first_author_surname,year,collapse = "")
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
entries <- vector("list", length(s_results))
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author_surname <- strsplit(authors[1], " ")[[1]][1] # Extract the surname of the first author
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
bibtex_label <- paste0(first_author_surname,year,collapse = "")
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
View(entries)
paste0("Barry","2022")
s_results <- py$s$results
entries <- vector("list", length(s_results))
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author_surname <- strsplit(authors[1], " ")[[1]][1] # Extract the surname of the first author
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
# Create the bibtex_label
bibtex_label <- ifelse(first_author_surname != "Unknown" && year != "No Year",
paste0(first_author_surname, year),
paste0("entry", i)) # Default label if surname or year is missing
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
entries <- vector("list", length(s_results))
for (i in seq_along(s_results)) {
result <- s_results[[i]]
authors <- ifelse(!is.null(result$author_names), result$author_names, c("Unknown"))
first_author <- strsplit(authors[1], " ")[[1]] # Split the first author's name into parts
first_author_surname <- first_author[length(first_author)] # Assume the last part is the surname
title <- ifelse(!is.null(result$title), result$title, "No Title")
journal <- ifelse(!is.null(result$publicationName), result$publicationName, "No Journal")
year <- ifelse(!is.null(result$coverDate), substr(result$coverDate, 1, 4), "No Year")
# Create the bibtex_label without any delimiter between surname and year
bibtex_label <- ifelse(first_author_surname != "Unknown" && year != "No Year",
paste0(first_author_surname, year),
paste0("entry", i)) # Default label if surname or year is missing
volume <- ifelse(!is.null(result$volume), result$volume, "N/A")
pages <- ifelse(!is.null(result$pageRange), result$pageRange, "N/A")
doi <- ifelse(!is.null(result$doi), result$doi, "No DOI")
entry <- sprintf("@article{%s,\n  author = {%s},\n  title = {%s},\n  journal = {%s},\n  year = {%s},\n  volume = {%s},\n  pages = {%s},\n  doi = {%s}\n}",
bibtex_label, paste(authors, collapse = " and "), title, journal, year, volume, pages, doi)
entries[[i]] <- entry
}
# Combine entries into a single character vector
bib_entries <- paste(unlist(entries), collapse = "\n\n")
writeLines(bib_entries, "references.bib")
# Install and load necessary packages
library(rugarch)
# Example: Simulate GARCH(1,1) process
set.seed(123)
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0)))
simulated_garch <- ugarchsim(spec, n.sim = 200)
# Install and load necessary packages
library(rugarch)
# Use European DAX index data
data("EuStockMarkets")
spec <- ugarchspec(
variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
distribution.model = "norm"
)
fit <- ugarchfit(spec = spec, data = EuStockMarkets[, "DAX"])
# Example: Simulate GARCH(1,1) process
set.seed(123)
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0)))
simulated_garch <- ugarchsim(spec, n.sim = 200)
# Install and load necessary packages
library(rugarch)
# Use European DAX index data
data("EuStockMarkets")
spec <- ugarchspec(
variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
distribution.model = "norm"
)
fit <- ugarchfit(spec = spec, data = EuStockMarkets[, "DAX"])
# Example: Simulate GARCH(1,1) process
set.seed(123)
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0)))
simulated_garch <- ugarchsim(fit = , n.sim = 200)
# Install and load necessary packages
library(rugarch)
# Use European DAX index data
data("EuStockMarkets")
spec <- ugarchspec(
variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
distribution.model = "norm"
)
fit <- ugarchfit(spec = spec, data = EuStockMarkets[, "DAX"])
# Example: Simulate GARCH(1,1) process
set.seed(123)
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0)))
simulated_garch <- ugarchsim(fit, n.sim = 200)
# Fit a GARCH model
fit_garch <- ugarchfit(spec = spec, data = simulated_garch@path$seriesSim)
simulated_garch@simulation
simulated_garch@model
# Install and load necessary packages
library(rugarch)
# Use European DAX index data
data("EuStockMarkets")
spec <- ugarchspec(
variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = TRUE),
distribution.model = "norm"
)
fit <- ugarchfit(spec = spec, data = EuStockMarkets[, "DAX"])
# Summary of the fitted model
summary(fit)
# Forecasting volatility
forecast_garch <- ugarchforecast(fit, n.ahead = 10)
plot(forecast_garch, which = "volatility")
plot(forecast_garch)
plot(forecast_garch)
# Plot the forecast
plot(forecast_values, which="all")
plot(forecast_garch,which="all")
plot(forecast_garch,which=3)
# Install caret package for creating train indices
#install.packages("caret")
# Load the caret package
library(caret)
# Split the data into training and testing sets
trainIndex <- createDataPartition(df$price, p = 0.8, list = FALSE)
# Set the seed for reproducibility
set.seed(123)
# Generate random dates from January 1, 2022 till December 31, 2022
dates <- seq(as.Date("2022-01-01"), as.Date("2022-12-31"), by = "day")
# Generate random prices with mean 100 and stddev 10
prices <- abs(rnorm(length(dates), 100, 10))
# Combine the dates and prices into a data frame
df <- data.frame(date = dates, price = prices)
# Install caret package for creating train indices
#install.packages("caret")
# Load the caret package
library(caret)
# Split the data into training and testing sets
trainIndex <- createDataPartition(df$price, p = 0.8, list = FALSE)
trainPrice <- df$price[trainIndex]
testPrice <- df$price[-trainIndex]
trainDF <- df[trainIndex, ]
testDF <- df[-trainIndex, ]
# Train a linear regression model using the date as the predictor
model <- lm(price ~ date, data = trainDF)
# Predict the test set prices
predictedTestPrice <- predict(model, testDF)
# Plot the actual and predicted prices
plot(testDF$date, testPrice, type = "l", col = "blue", xlab = "Time", ylab = "Price", main = "Predictions vs Actual Prices")
# Add lines for predicted prices
lines(testDF$date, predictedTestPrice, col = "red")
# Add a legend
legend("topright", legends = c("Actual", "Predicted"), lty = 1, col = c("blue", "red"))
library(ggplot2)
# Assuming testDF, testPrice, and predictedTestPrice are already defined
# Combine the actual and predicted prices into one data frame
data_to_plot <- data.frame(
Date = testDF$date,
Price = c(testPrice, predictedTestPrice),
Type = c(rep("Actual", length(testPrice)), rep("Predicted", length(predictedTestPrice)))
)
# Create the plot using ggplot
ggplot(data_to_plot, aes(x = Date, y = Price, color = Type)) +
geom_line() +
labs(x = "Time", y = "Price", title = "Predictions vs Actual Prices") +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
theme_minimal()
# Set the seed for reproducibility
set.seed(123)
# Generate random data for 5 stocks with 100 weekly observations
n <- 100
p <- 5
mu <- c(rep(0.05, p)) # Means for all stocks
Sigma <- matrix(runif(p^2, min = 0.1, max = 0.5), p, p) # Variance-covariance matrix
Sigma <- Sigma %*% t(Sigma) # Ensure symmetry
returns <- mvrnorm(n, mu, Sigma) # Generate random returns
# Set the seed for reproducibility
set.seed(123)
library(MASS)
# Generate random data for 5 stocks with 100 weekly observations
n <- 100
p <- 5
mu <- c(rep(0.05, p)) # Means for all stocks
Sigma <- matrix(runif(p^2, min = 0.1, max = 0.5), p, p) # Variance-covariance matrix
Sigma <- Sigma %*% t(Sigma) # Ensure symmetry
returns <- mvrnorm(n, mu, Sigma) # Generate random returns
returns <- t(returns) # Convert to the right format
names(returns) <- paste0("stock_", 1:p) # Name columns
returns <- as.data.frame(returns) # Cast to data frame
returns$date <- seq(as.Date("2022-01-01"), by = "week", length.out = n) # Add date column
# Set the seed for reproducibility
set.seed(123)
library(MASS)
# Generate random data for 5 stocks with 100 weekly observations
n <- 100
p <- 5
mu <- c(rep(0.05, p)) # Means for all stocks
Sigma <- matrix(runif(p^2, min = 0.1, max = 0.5), p, p) # Variance-covariance matrix
Sigma <- Sigma %*% t(Sigma) # Ensure symmetry
returns <- mvrnorm(n, mu, Sigma) # Generate random returns
returns <- t(returns) # Convert to the right format
names(returns) <- paste0("stock_", 1:p) # Name columns
returns <- as.data.frame(returns) # Cast to data frame
returns$date <- seq(as.Date("2022-01-01"), by = "week", length.out = p) # Add date column
returns <- gather(returns, Key = stock, Value = Return, -date) # Reshape to wide format
library(dplyr)
# Set the seed for reproducibility
set.seed(123)
library(MASS)
library(dplyr)
# Generate random data for 5 stocks with 100 weekly observations
n <- 100
p <- 5
mu <- c(rep(0.05, p)) # Means for all stocks
Sigma <- matrix(runif(p^2, min = 0.1, max = 0.5), p, p) # Variance-covariance matrix
Sigma <- Sigma %*% t(Sigma) # Ensure symmetry
returns <- mvrnorm(n, mu, Sigma) # Generate random returns
returns <- t(returns) # Convert to the right format
names(returns) <- paste0("stock_", 1:p) # Name columns
returns <- as.data.frame(returns) # Cast to data frame
returns$date <- seq(as.Date("2022-01-01"), by = "week", length.out = p) # Add date column
returns <- gather(returns, Key = stock, Value = Return, -date) # Reshape to wide format
library(tidyverse)
returns <- pivot_wider(returns, names_from = stock, values_from = Return, -date) # Reshape to wide format
returns$date <- seq(as.Date("2022-01-01"), by = "week", length.out = p) # Add date column
View(returns)
returns$date <- seq(as.Date("2022-01-01"), by = "week", length.out = p) # Add date column
returns <- pivot_wider(returns, names_from = stock, values_from = Return, -date) # Reshape to wide format
returns <- pivot_longer(returns,-date, names_to = stock, values_to = Return) # Reshape to wide format
returns <- pivot_longer(returns,-date, names_to = 'stock', values_to = 'Return') # Reshape to wide format
returns$Return <- as.numeric(returns$Return) # Change the type of Returns column
# Install and load the cluster package
#install.packages("cluster")
library(cluster)
# Run k-means clustering with 3 clusters and 25 initialization attempts
kmeansRes <- kmeans(returns[, -1], centers = 3, nstart = 25)
returns[, -1]
# Run k-means clustering with 3 clusters and 25 initialization attempts
kmeansRes <- kmeans(returns$Return, centers = 3, nstart = 25)
# Add clusters to the returns data frame
returns$Cluster <- factor(kmeansRes$cluster)
# Load ggplot2 for visualization
library(ggplot2)
# Group data by stock, cluster, and date
portfolios <- returns %>%
mutate(Week = floor((as.numeric(date) - min(as.numeric(date))) / 7)) %>%
group_by(Week, stock, Cluster) %>%
summarise(avg_return = mean(Return))
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios, aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock, ncol = 1) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster")
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios, aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster")
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios, aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 3))
View(portfolios)
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios |> select(stock %in% c("V1","V10","V100")) , aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 8))
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios |> filter(stocks %in% c("V1","V10","V100")) , aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 8))
# Group data by stock, cluster, and date
portfolios <- returns %>%
mutate(Week = floor((as.numeric(date) - min(as.numeric(date))) / 7)) %>%
group_by(Week, stock, Cluster) %>%
summarise(avg_return = mean(Return)) |>
ungroup()
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios |> filter(stocks %in% c("V1","V10","V100")) , aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 8))
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios |> filter(stock %in% c("V1","V10","V100")) , aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 8))
# Plot boxplots for each stock and week, colored by cluster
ggplot(portfolios |> filter(stock %in% c("V1","V13","V99","V50")) , aes(factor(Week), avg_return, color = factor(Cluster))) +
geom_boxplot() +
facet_wrap(~ stock) +
labs(title = "Returns by Stock and Cluster for 3 of 100 stocks", x = "Week", y = "Avg. Return", color = "Cluster") +
theme(text = element_text(size = 8))
p <- rnorm(n, mean = 0.05, sd = 0.1) # Log return sequence
prices <- exp(cumsum(p)) # Actual prices
actions <- ifelse(diff(log(prices)) > 0, 1, -1) # Buy (-1) or Sell (1)
head(data.frame(Prices = prices, Actions = actions))
# Generate synthetic financial data
n <- 1000
p <- rnorm(n, mean = 0.05, sd = 0.1) # Log return sequence
prices <- exp(cumsum(p)) # Actual prices
actions <- ifelse(diff(log(prices)) > 0, 1, -1) # Buy (-1) or Sell (1)
head(data.frame(Prices = prices, Actions = actions))
head(data.frame(Prices = prices, Actions = c(NA,actions))
library(rl)
head(data.frame(Prices = prices, Actions = c(NA,actions)))
library(rl)
devtools::install_github("smilesun/rlR")
#devtools::install_github("smilesun/rlR")
#library(rl)
# Define state space
state_size <- ncol(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices)))), k = 1)))
# Define state space
state_size <- ncol(as.matrix(lag(t(as.matrix(data.frame(Prices = prices)))), k = 1)))
# Define state space
state_size <- ncol(as.matrix(lag(t(as.matrix(data.frame(Prices = prices)))), k = 1))
action_size <- 2
# Initialize Q matrix
Q <- matrix(rep(NA, state_size * action_size), nrow = state_size, ncol = action_size)
# Set hyperparameters
alpha <- 0.1 # Learning rate
epsilon <- 0.1 # Exploration probability
num_episodes <- 1000 # Number of episodes
discount_factor <- 0.95 # Discount factor
# Implement Q-learning
for (episode in seq(num_episodes)) {
state <- head(as.numeric(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices))))), k = 1)), 1)
done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- argmax(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices))))), k = 1)), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
# Implement Q-learning
for (episode in seq(num_episodes)) {
state <- head(as.numeric(as.matrix(lag(t(as.matrix((data.frame(Prices = prices))))), k = 1)), 1)
done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- argmax(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.bind(data.frame(Prices = prices))))), k = 1)), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.frame(Prices = prices))))), k = 1), 1)
#devtools::install_github("smilesun/rlR")
#library(rl)
# Define state space
state_size <- ncol(as.matrix(lag(t(as.matrix(data.frame(Prices = prices)))), k = 1))
action_size <- 2
# Initialize Q matrix
Q <- matrix(rep(NA, state_size * action_size), nrow = state_size, ncol = action_size)
# Set hyperparameters
alpha <- 0.1 # Learning rate
epsilon <- 0.1 # Exploration probability
num_episodes <- 1000 # Number of episodes
discount_factor <- 0.95 # Discount factor
# Implement Q-learning
for (episode in seq(num_episodes)) {
state <- head(as.numeric(as.matrix(lag(t(as.matrix((data.frame(Prices = prices))))), k = 1)), 1)
done <- FALSE
while (!done) {
if (runif(1) <= epsilon) {
# Explore randomly
action <- sample(seq(-1, 1), size = 1)
} else {
# Choose greedily
action <- which.max(Q[state,])
}
next_state <- tail(as.numeric(as.matrix(lag(t(as.matrix(data.frame(Prices = prices))))), k = 1), 1)
reward <- actions[episode] * (tail(prices, 1) / prices[episode + 1] - 1)
# Update Q-value
old_q <- Q[state, action]
new_q <- reward + discount_factor * max(Q[next_state,])
delta <- new_q - old_q
Q[state, action] <- old_q + alpha * delta
state <- next_state
done <- episode == num_episodes || length(states) >= n
}
}
reticulate::repl_python()
